{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00c0fb68",
      "metadata": {
        "id": "00c0fb68"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "from collections import deque\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307e8097",
      "metadata": {
        "id": "307e8097"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', 20)\n",
        "pd.set_option('display.max_columns', 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fca378f4",
      "metadata": {
        "id": "fca378f4"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "file = './csv/PensionReform.csv'\n",
        "df = pd.read_csv(file, dtype={\"id\":str,\"conversation_id\":str,\"ref_id\":str,\"ref_author_id\":str, \"in_reply_to_user_id\":str, \"author_id\":str})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a35a76f",
      "metadata": {
        "id": "5a35a76f"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26a2c7e6",
      "metadata": {},
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e918d13",
      "metadata": {},
      "source": [
        "You can skip this section if not necessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5c7627",
      "metadata": {
        "id": "2a5c7627"
      },
      "outputs": [],
      "source": [
        "def update_text_columns(row):\n",
        "    if pd.notna(row['ref_note_tweet']) and row['ref_type'] == \"retweeted\":\n",
        "        return row['ref_note_tweet']\n",
        "    elif pd.notna(row['ref_text']) and row['ref_type'] == \"retweeted\":\n",
        "        return row['ref_text']\n",
        "    return row['text']\n",
        "\n",
        "df['text'] = df.apply(update_text_columns, axis=1)\n",
        "df.drop(columns=['ref_note_tweet'], inplace=True)\n",
        "df.rename(columns={'ref_note_tweet': 'ref_text'}, inplace=True)\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c424690f",
      "metadata": {
        "id": "c424690f"
      },
      "outputs": [],
      "source": [
        "df['retweet_count'] = np.int32(0)\n",
        "df['reply_count'] = np.int32(0)\n",
        "df['like_count'] = np.int32(0)\n",
        "df['quote_count'] = np.int32(0)\n",
        "df['bookmark_count'] = np.int32(0)\n",
        "df['impression_count'] = np.int32(0)\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e058a688",
      "metadata": {
        "id": "e058a688"
      },
      "outputs": [],
      "source": [
        "def extract_metrics(row):\n",
        "    str_dic = ast.literal_eval(row['public_metrics'])\n",
        "    row['retweet_count'] = str_dic['retweet_count']\n",
        "    row['reply_count'] = str_dic['reply_count']\n",
        "    row['like_count'] = str_dic['like_count']\n",
        "    row['quote_count'] = str_dic['quote_count']\n",
        "    row['bookmark_count'] = str_dic['bookmark_count']\n",
        "    row['impression_count'] = str_dic['impression_count']\n",
        "    return row\n",
        "\n",
        "df = df.apply(extract_metrics, axis=1)\n",
        "df.drop(columns=['public_metrics'], inplace=True)\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c38d3ef",
      "metadata": {},
      "source": [
        "# Classification model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d01702",
      "metadata": {
        "id": "65d01702"
      },
      "outputs": [],
      "source": [
        "df['likert_scale_Q1'] = np.nan\n",
        "df['r_tag_Q1'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c872486",
      "metadata": {
        "id": "7c872486"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"OPENAI4_API_KEY\")\n",
        "if api_key is None:\n",
        "    raise ValueError(\"OPENAI4_API_KEY not found in environment variables\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Classification Function\n",
        "def openAI_classificator(prompt, message, model=\"gpt-4.1-mini-2025-04-14\"):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": prompt\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": message\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=10,\n",
        "            temperature=0.0,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content, response.usage.total_tokens\n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        match = re.search(r\"Requested (\\d+)\\.\", str(e))\n",
        "        if match:\n",
        "            requested_tokens = int(match.group(1))\n",
        "        else:\n",
        "            requested_tokens = 0\n",
        "\n",
        "        return np.nan, requested_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b406d152",
      "metadata": {
        "id": "b406d152"
      },
      "outputs": [],
      "source": [
        "# NOTE: Pensional reform context and subject example\n",
        "\n",
        "context = \"La reforma pensional en Colombia es un tema recurrente en la agenda política y social\" \\\n",
        "\" del país debido a la necesidad de abordar la sostenibilidad y la equidad del sistema de\" \\\n",
        "\" pensiones. El sistema actual combina un régimen de prima media (RPM), administrado por el\" \\\n",
        "\" Estado a través de Colpensiones, y un régimen de ahorro individual (RAIS), manejado por\" \\\n",
        "\" fondos privados. Sin embargo, el acceso a una pensión digna es limitado para muchos trabajadores,\" \\\n",
        "\" especialmente aquellos en la informalidad o con bajos ingresos. La reforma busca ampliar la\" \\\n",
        "\" cobertura, mejorar la equidad entre los diferentes regímenes y asegurar la sostenibilidad\" \\\n",
        "\" financiera a largo plazo.\"\n",
        "\n",
        "subject = \"Apoya la reforma pensional en Colombia propuesta por el gobierno de Colombia.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d237901d",
      "metadata": {
        "id": "d237901d"
      },
      "outputs": [],
      "source": [
        "def basic_prompt(context, subject):\n",
        "    return f\"\"\"\n",
        "    Contexto: {context}\n",
        "\n",
        "    Instrucción: Clasifica el siguiente mensaje en la escala de Likert en relación con la siguiente afirmación: \\\"{subject}\\\". Tambien indica si el mensaje tiene relacion con la afirmacion o no (1 o 0).\n",
        "    Las opciones son: 1: 'Completamente en desacuerdo', 2: 'En desacuerdo', 3: 'Ni de acuerdo ni en desacuerdo', 4: 'De acuerdo', 5: 'Completamente de acuerdo'.\n",
        "    Solo responde con una de las etiquetas mencionadas sin ningún texto adicional y si tiene relacion el texto no. Por ejemplo \"2,1\" para \"En desacuerdo\" y \"si tiene relacion con el tema\" o \"4,0\" (De acuerdo y no tiene relacion).\n",
        "    \"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "160ba88d",
      "metadata": {
        "id": "160ba88d"
      },
      "outputs": [],
      "source": [
        "def reply_prompt(context, subject, replied_message):\n",
        "    return f\"\"\"\n",
        "    Contexto: {context}\n",
        "\n",
        "    Instrucción: Clasifica el siguiente mensaje en la escala de Likert en relación con la siguiente afirmación: \\\"{subject}\\\". Tambien indica si el mensaje tiene relacion con la afirmacion o no (1 o 0).\n",
        "    Las opciones son: 1: 'Completamente en desacuerdo', 2: 'En desacuerdo', 3: 'Ni de acuerdo ni en desacuerdo', 4: 'De acuerdo', 5: 'Completamente de acuerdo'.\n",
        "    Ten en cuenta tambien que el mensaje al que responde es: \\\"{replied_message}\\\"\n",
        "    Solo responde con una de las etiquetas mencionadas sin ningún texto adicional y si tiene relacion el texto no. Por ejemplo \"2,1\" para \"En desacuerdo\" y \"si tiene relacion con el tema\" o \"4,0\" (De acuerdo y no tiene relacion).\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3473ca64",
      "metadata": {
        "id": "3473ca64"
      },
      "outputs": [],
      "source": [
        "# Max token per minute\n",
        "MAX_TOKENS_PER_MINUTE = 450000 # Rate limit tier 2 -> 450k tokens/minute in model gpt-4.1-2025-04-14\n",
        "\n",
        "# save (timestamp, tokens) of each request in a deque\n",
        "token_window = deque()\n",
        "\n",
        "def clean_token_window():\n",
        "    #delete the values older than 60 seconds\n",
        "    current_time = time.time()\n",
        "    while token_window and (current_time - token_window[0][0]) > 60:\n",
        "        token_window.popleft()\n",
        "\n",
        "def wait_if_needed(new_tokens):\n",
        "    clean_token_window()\n",
        "    current_tokens = sum(tokens for _, tokens in token_window)\n",
        "\n",
        "    if current_tokens + new_tokens > MAX_TOKENS_PER_MINUTE:\n",
        "        excess = (current_tokens + new_tokens) - MAX_TOKENS_PER_MINUTE\n",
        "        print(f\"[WAIT] amount of tokens exceded ({excess}). Waiting...\")\n",
        "\n",
        "        # Calculate the time to wait based on the excess tokens\n",
        "        time_to_wait = 60 - (time.time() - token_window[0][0])\n",
        "        time.sleep(time_to_wait)\n",
        "        clean_token_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21473af5",
      "metadata": {},
      "source": [
        "# Messages classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016d1261",
      "metadata": {
        "id": "016d1261"
      },
      "outputs": [],
      "source": [
        "# id's of rows that are not retweets\n",
        "df_nrt = df[df['ref_type'] != 'retweeted']\n",
        "nrt_ids = df_nrt['id'].to_list(); #nrt_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a300942e",
      "metadata": {
        "id": "a300942e"
      },
      "outputs": [],
      "source": [
        "def classify_message(context,subject,ids, class_type=2):\n",
        "    i = 0\n",
        "    for id in ids:\n",
        "        if i % 30 == 0:\n",
        "            print(f\"Processing {i} of {len(ids)}\")\n",
        "\n",
        "        row = df[df[\"id\"] == id].iloc[0]\n",
        "        text = row['text']\n",
        "\n",
        "        try:\n",
        "            wait_if_needed(850)\n",
        "\n",
        "            if class_type == 1:\n",
        "                response = openAI_classificator(basic_prompt(context, subject), text, model=\"gpt-4o-2024-08-06\")[0]\n",
        "\n",
        "            elif class_type == 2:\n",
        "                #classify tweets\n",
        "                if pd.isna(row['ref_type']):\n",
        "                    response = openAI_classificator(basic_prompt(context, subject), text, model=\"gpt-4o-2024-08-06\")[0]\n",
        "\n",
        "                #classify replies and quotes\n",
        "                else:\n",
        "                    ref_text = row['ref_text']\n",
        "                    response = openAI_classificator(reply_prompt(context, subject,ref_text), text, model=\"gpt-4o-2024-08-06\")[0]\n",
        "\n",
        "            classification, r_tag = response.strip().split(\",\")\n",
        "\n",
        "            df.loc[df[\"id\"] == id, 'likert_scale_Q1'] = classification\n",
        "            df.loc[df[\"id\"] == id,'r_tag_Q1'] = r_tag\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing id {id}: {e}\")\n",
        "            row['likert_scale_Q1'] = \"error\"\n",
        "            row['r_tag_Q1'] = \"error\"\n",
        "\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f04ec35",
      "metadata": {
        "id": "7f04ec35"
      },
      "outputs": [],
      "source": [
        "# Step 1: Classify all messages except retweets\n",
        "nrt_ids = df_nrt['id'].to_list(); #nrt_ids\n",
        "\n",
        "classify_message(context, subject, nrt_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b180d3",
      "metadata": {
        "id": "f4b180d3"
      },
      "outputs": [],
      "source": [
        "# Step 2: Check if any of the messages classified was retweeted to assing the classification value to the retweets\n",
        "# and not classify them again\n",
        "aux_count = []\n",
        "for id in nrt_ids:\n",
        "    aux = df[(df['ref_id'] == str(id)) & (df['ref_type'] == 'retweeted')]\n",
        "    aux_count.append(len(aux))\n",
        "\n",
        "print(f\"Number of retweets already classified: {sum(aux_count)}\")\n",
        "\n",
        "i = 0\n",
        "for id in nrt_ids:\n",
        "    if i % 30 == 0:\n",
        "        print(f\"Processing {i} of {len(nrt_ids)}\")\n",
        "\n",
        "    classification = df.loc[df['id'] == id, 'likert_scale_Q1'].values[0]\n",
        "    r_tag = df.loc[df['id'] == id, 'r_tag_Q1'].values[0]\n",
        "\n",
        "    df.loc[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted'), 'likert_scale_Q1'] = classification\n",
        "    df.loc[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted'), 'r_tag_Q1'] = r_tag\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f95363e8",
      "metadata": {
        "id": "f95363e8"
      },
      "outputs": [],
      "source": [
        "# Step 3: Identify unique ref_ids in the dataframe\n",
        "unique_ref_ids = df['ref_id'].unique()\n",
        "unique_ref_ids = unique_ref_ids[~pd.isna(unique_ref_ids)]\n",
        "\n",
        "# Identify ref_id without classification\n",
        "ref_dif = []\n",
        "ref_count = []\n",
        "\n",
        "for id in unique_ref_ids:\n",
        "    aux = df[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted')]\n",
        "\n",
        "    if not aux.empty:\n",
        "        first = aux.iloc[0]\n",
        "        if not pd.notna(first.likert_scale_Q1):\n",
        "            ref_count.append(len(aux))\n",
        "            ref_dif.append(first.ref_id)\n",
        "\n",
        "print(f\"Number of retweets without classification: {sum(ref_count)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab80b18",
      "metadata": {
        "id": "eab80b18"
      },
      "outputs": [],
      "source": [
        "# Step 4: Classify the unique retweets that have not been classified yet\n",
        "# and assign the classification to the retweets\n",
        "print(f\"Tweets needed to classify: {len(ref_dif)}. Classifying...\")\n",
        "\n",
        "i = 0\n",
        "for id in ref_dif:\n",
        "    if i % 30 == 0:\n",
        "        print(f\"Processing {i} of {len(ref_dif)}\")\n",
        "\n",
        "    row = df[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted')].iloc[0]\n",
        "    text = row['text']\n",
        "\n",
        "    response = openAI_classificator(basic_prompt(context, subject), text, model=\"gpt-4o-2024-08-06\")[0]\n",
        "    classification, r_tag = response.strip().split(\",\")\n",
        "\n",
        "\n",
        "    df.loc[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted'), 'likert_scale_Q1'] = classification\n",
        "    df.loc[(df['ref_id'] == id) & (df['ref_type'] == 'retweeted'),'r_tag_Q1'] = r_tag\n",
        "\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6ce6062",
      "metadata": {
        "id": "b6ce6062"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39474e95",
      "metadata": {
        "id": "39474e95"
      },
      "outputs": [],
      "source": [
        "save_path = './csv/PensionReform.csv'\n",
        "df.to_csv(save_path, index=False)\n",
        "# NOTE: ORIGINAL MESSAGES HAVE BEEN DELETED IN THE SHARED DATASETS TO AVOID data-exposure risks, and all author IDs are anonymized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494e22cb",
      "metadata": {
        "id": "494e22cb"
      },
      "outputs": [],
      "source": [
        "df['likert_scale_Q1'].value_counts()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
